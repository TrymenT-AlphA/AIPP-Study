# 并行程序设计导论 读书笔记

> https://github.com/TrymenT-AlphA/AIPP-Study

## 第一章 为什么要并行计算

由于物理上的限制，传统单处理器性能提升的速度不断降低，芯片制造商开始转向**多核**集成电路

产生的影响：大多数**串行**程序并**不会**因为简单地增加更多的处理器获得极大的性能提升

引发的问题：

1. 为什么要关心并行？

2. 为什么厂商不能研制更快的单处理器系统？为什么要研制并行系统？为什么要研制多处理器系统？

3. 为什么不能编写程序，将**串行**程序转换成**并行**程序？

### 1.1 为什么需要不断提升的性能

我们要考虑的问题需要更强大的计算能力：气候模拟，蛋白质折叠，药物发现，能源研究，数据分析

### 1.2 为什么需要构建并行系统

单处理器性能提高的主要原因是日益增加的集成电路晶体管密度，同时这也导致了能耗增加，大部分能量以热量的形式散失，当电路变得太热就会变得不可靠，而空气冷却的集成电路散热能力已经达到了极限，从而限制单处理器性能进一步提高

解决方法：用并行利用不断增加的晶体管密度

### 1.3 为什么需要编写并行程序

编写并行程序是为了利用多核处理器

翻译程序不可能担负起将所有的串行程序并行化的重任

### 1.4 怎样编写并行程序

```C
int sum = 0;
int i;
for (i = 0; i < n; i++){
    x = Compute_next_value(...);
    sum += x
}
```

```C
int my_sum = 0;
int my_i;
for (my_i = my_first_i; my_i < my_last_i; my_i++){
    my_x = Compute_next_value(...);
    my_sum += my_x;
}
```

#### 1.4.1 数据并行

将待解决问题所需处理的数据分配到各个核上执行

#### 1.4.2 任务并行

将待解决问题所需执行的各个任务分配到各个核上执行

#### 1.4.3 通信、负载平衡、同步

为了更好的协调各个处理器工作

通信：一个或多个核将自己的部分和结果发送给其他的核

负载平衡：给每个核分配大致相同数目的数据计算

同步：解决数据依赖，数据竞争

### 1.5 我们将做什么

#### 1.5.1 三个C语言的扩展

1. 消息传递接口（Message-Passing Interface, MPI）
2. POSIX线程（POSIX threads, Pthread）
3. OpenMP

#### 1.5.2 两种并行系统

1. 共享内存系统：各个核能够共享访问计算机的内存
2. 分布式系统：每个核都有自己的私有内存

![image-20220809155025413](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220809155025413.png)

### 1.6 并发、并行、分布式

并发：一个程序的多个任务，在同一时间段内同时执行（CPU与IO）

并行：一个程序同时在多个核上执行多个任务，这些核通常在物理上紧密相连（紧耦合）

分布式：在多个计算机上执行多个任务，计算机之间相隔较远，并有独立的程序（松耦合）

### 1.7 本书的其余部分

...

### 1.8 警告

...

### 1.9 字体约定

...

## 第二章 并行硬件和并行软件

### 2.1 背景知识

#### 2.1.1 冯·诺依曼结构

主存+中央处理单元（控制单元+算术逻辑单元+寄存器+PC）

![image-20220809154920098](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220809154920098.png)

#### 2.1.2 进程、多任务及线程

进程是操作系统对处理器+主存+I/O设备的抽象，一个进程提供了程序运行所需的资源

![image-20220809160410598](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220809160410598.png)

![image-20220809160603479](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220809160603479.png)

多任务是在操作系统的调度下，单个CPU也能做到同时运行多个任务

![image-20220809160821412](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220809160821412.png)

线程也被称作‘轻量级进程’，同一进程创建的多个线程，除了拥有独立的堆之外，共享一切资源

### 2.2 对冯·诺依曼模型的改进

解决冯·诺依曼瓶颈

三种措施：缓存（caching）、虚拟内存、低层次并行

#### 2.2.1 Cache基础知识

利用局部性原理（时间局部性和空间局部性），将部分数据或代码存放在访问较快的特殊存储器中，Cache是对主存的拷贝，实际的存储器层次结构如图

![image-20220809161520931](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220809161520931.png)

#### 2.2.2 Cache映射

Cache的组织方法：直接映射，全相联，n路组相联

Cache替换算法：FIFO，FLU，ALU等

![image-20220809161352319](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220809161352319.png)

#### 2.2.3 Cache和程序：一个实例

| 高速缓存行 |             |             |             |             |
| ---------- | ----------- | ----------- | ----------- | ----------- |
| 0          | A\[0\]\[0\] | A\[0\]\[1\] | A\[0\]\[2\] | A\[0\]\[3\] |
| 1          | A\[1\]\[0\] | A\[1\]\[1\] | A\[1\]\[2\] | A\[1\]\[3\] |
| 2          | A\[2\]\[0\] | A\[2\]\[1\] | A\[2\]\[2\] | A\[2\]\[3\] |
| 3          | A\[3\]\[0\] | A\[3\]\[1\] | A\[3\]\[2\] | A\[3\]\[3\] |

```C
double A[MAX][MAX], x[MAX], y[MAX];
...;
/* Initialize A and x, assign y = 0 */
...;
/* First pair of loops */ /* 这样有更好的空间局部性，是Cache友好的 */
for (i = 0; i < MAX; i++)
    for (j = 0; j < MAX; j++)
        y[i] += A[i][j]*x[j];
...;
/* Assign y = 0 */
...;
/* Second pair of loops */
for (j = 0; j < MAX; i++)
    for (i = 0; i < MAX; j++)
        y[i] += A[i][j]*x[j];
```

#### 2.2.4 虚拟存储器

![image-20220809161626424](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220809161626424.png)

#### 2.2.5 指令级并行（ILP）

##### 2.2.5.1 流水线：将功能单元分阶段安排

常见的五级流水线将指令的执行分为五个阶段：取指、译码、执行、访存、写回

流水线的周期由各个阶段中执行时间最长的阶段决定

![image-20220809163540898](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220809163540898.png)

##### 2.2.5.2 多发射：让多条指令同时启动

通过复制功能单元来同时执行程序中的不同指令

通过预测找到能够同时执行的指令

静态多发射：编译时调度

动态多发射：运行时调度

支持动态发射的处理器称为超标量处理器

#### 2.2.6 硬件多线程（TLP）

线程级并行通过同时执行不同的线程来提供并行性

避免频繁切换线程带来的损失

### 2.3 并行硬件（程序员可见）

冯·诺伊曼系统是单指令流单数据流（Single Instruction Stream， Single Data Stream，SISD）

#### 2.3.1 SIMD系统

单指令多数据流，对多个数据执行相同的指令（向量计算）

向量处理器：对数组或者数据向量进行操作，如GPU

#### 2.3.2 MIMD系统

多指令多数据流，同时多个指令流在多个数据流上操作

一般是异步的，每个处理器按照自己的节奏运行，没有全局时钟

![image-20220810095140861](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220810095140861.png)

一致内存访问系统

![image-20220810095415208](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220810095415208.png)

非一致内存访问系统

![image-20220810095436151](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220810095436151.png)

#### 2.3.3 互连网络

用于将计算机中各节点连接，包括处理器，存储设备和其他设备

##### 2.3.3.1 共享内存互连网络

总线

![image-20220810100132177](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220810100132177.png)

交叉开关矩阵

![image-20220810100230741](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220810100230741.png)

##### 2.3.3.2 分布式内存互连网络

直接互连：将每个节点直接与交换器相连

![image-20220810101131033](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220810101131033.png)

![image-20220810101244108](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220810101244108.png)

间接互连：每个节点与输入链路和输出链路相连，通过独立的交换网络实现互连

![image-20220810101209851](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220810101209851.png)

![image-20220810101223136](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220810101223136.png)

等分宽度：将网络等分为两部分，两部分可同时通信的链路数目（按最坏情况考虑），用于衡量‘连接性’

下图等分宽度为2而不是4

![image-20220810101456335](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220810101456335.png)

链路带宽：该链路传输数据的速度

等分带宽：和‘等分宽度’类似，可同时通信的带宽

##### 2.3.3.3 延迟和带宽

延迟：从发送源开始传输数据到目的地开始接受数据之间的时间

带宽：目的地在开始接受数据后接受数据的速度

#### 2.3.4 Cache一致性

由于每个核有自己的独立的Cache，当一个核修改数据时，其他核并不知道，而Cache是主存的拷贝，因此导致Cache的正确性被破坏

![image-20220810101914440](C:\Users\ChongKai\AppData\Roaming\Typora\typora-user-images\image-20220810101914440.png)

##### 2.3.4.1 监听Cache一致性协议

每次修改时广播告知其他所有核

##### 2.3.4.2 基于目录的Cache一致性协议

维护一个叫目录的数据结构，需要大量的额外存储空间，但当一个Cache变量更新时，只要与存储这个变量的核交涉

##### 2.3.4.3 伪共享

两个线程同时对同一个高速缓存行进行操作，由于每个核有独立的高速缓存，每次前一线程写入后，其他核的该缓存行都会失效，其他核必须从主存中更新高速缓存行，产生大量不必要的访存操作，造成性能损失

```C
/* Private variables */
int i, j, iter_count;

/* Shared variables initialized by one core */
int m, n, core_count;
double y[m];

iter_count = m / core_count;

/* Core 0 */
for (i = 0; i < iter_count; i++)
    for (j = 0; j < n; j++)
        y[i] += f(i, j);

/* Core 1 */
for (i = iter_count+1; i < 2*iter_count; i++)
    for (j = 0; j < n; j++)
        y[i] += f(i, j);
```

#### 2.3.5 共享内存与分布式内存

...

### 2.4 并行软件

#### 2.4.1 注意事项

我们主要关注单程序多数据流SPMD（Single Program，Multiple Data，SPMD）

#### 2.4.2 进程或线程的协调

安排进程/线程之间的同步

安排进程/线程之间的通信

#### 2.4.3 共享内存

##### 2.4.3.1 动态线程和静态线程

动态线程：有一个主线程，运行时创建若干个子线程进行工作，工作结束后合并回主线程

静态线程：主线程在完成必要的设置后派生出所有的线程，直到程序结束前，所有的线程同时运行

##### 2.4.3.2 非确定性

多个进程/线程尝试访问同一个资源，会产生竞争

解决方法：互斥锁，互斥量，信号量，原子性

##### 2.4.3.3 线程安全性

有些库函数不是线程安全的

#### 2.4.4 分布式内存

##### 2.4.4.1 消息传递

由一个进程Send，另一进程Receive，两函数都是阻塞的

##### 2.4.4.2 单向通信

复制前同步，利用标志位，标志该量已经更新

##### 2.4.4.3 划分全局地址空间的语言

...

#### 2.4.5 混合系统编程

在节点上使用共享内存API，在节点间使用分布式内存API

### 2.5 输入和输出

* 在分布式内存程序中，只有进程0能够访问stdin。在共享内存程序中，只有主线程或线程0能够访问stdin
* 在分布式内存和共享内存系统中，所有进程/线程都能够访问stdout和stderr
* 大多数情况下，只有一个进程/线程会将结果输出到stdout，输出调试程序除外
* 只有一个进程/线程会尝试访问一个除stdin，stdout，stderr之外的文件，没有两个进程/线程能同时打开相同的文件
* 调试程序输出在生成输出结果时，应包括进程/线程的序号或进程标识符 

### 2.6 性能

#### 2.6.1 加速比和效率

加速比：$S=\frac{T_{并行}}{T_{串行}}$

效率：$E=\frac{S}{p}$

并行开销：$T_{并行}=T_{串行}/p+T_{开销}$

#### 2.6.2 阿姆达尔定律

大致上，除非一个串行程序执行几乎全部都并行化，否则，无论有多少可以利用的核，通过并行化产生的加速比都是受限的

#### 2.6.3 可扩展性

强可扩展：增加进程/线程数，不增加问题的规模，效率不变

若可扩展：增加进程/线程数，等比例增加问题的规模，效率不变

#### 2.6.4 计时

...

### 2.7 并行程序设计

1. 划分。将要执行的指令核数据按照计算部分拆分成多个小任务。
2. 通信。确定上一步识别出的人物之间需要执行哪些通信
3. 凝聚或聚合。将第一步确定的任务和通信结合成更大的任务
4. 分配。将任务均衡分配到各个进程/线程中

### 2.8 编写和运行并行程序

...

### 2.9 假设

...

### 2.10 小结

...